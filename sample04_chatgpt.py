import discord
from discord.ext import commands
import os
import asyncio
import logging
import time
from dotenv import load_dotenv
from openai import OpenAI
import datetime
import json
import tiktoken

load_dotenv()

# GPT-4é€£æºDiscordãƒœãƒƒãƒˆ
intents = discord.Intents.all()
intents.message_content = True
intents.guilds = True
intents.guild_messages = True

bot = commands.Bot(command_prefix='!', intents=intents)

# å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«IDï¼ˆæŒ‡å®šã•ã‚ŒãŸéƒ¨å±‹ï¼‰
TARGET_CHANNEL_ID = 1418512165165465600

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = None
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

if OPENAI_API_KEY:
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        print(f'[SETUP] OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†')
    except Exception as e:
        print(f'[ERROR] OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å¤±æ•—: {e}')
else:
    print('[WARNING] OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')

# ãƒˆãƒ¼ã‚¯ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
try:
    # GPT-4ç”¨ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
    encoding = tiktoken.encoding_for_model("gpt-4")
    print('[SETUP] Tiktokenã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–å®Œäº† (GPT-4å¯¾å¿œ)')
except Exception as e:
    print(f'[WARNING] Tiktokenã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–å¤±æ•—: {e}')
    encoding = None

class ChatGPTResponder:
    def __init__(self, openai_client):
        self.client = openai_client
        self.is_responding = False
        self.response_history = []  # ä¼šè©±å±¥æ­´ã‚’ä¿æŒ
        self.max_tokens = 4000  # GPT-4ç”¨æœ€å¤§å¿œç­”ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        self.max_context_tokens = 8192  # GPT-4ç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        self.retry_count = 3  # ãƒªãƒˆãƒ©ã‚¤å›æ•°
        self.rate_limit_delay = 1  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ™‚ã®å¾…æ©Ÿæ™‚é–“
        
    def count_tokens(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        if encoding:
            try:
                return len(encoding.encode(text))
            except Exception:
                return len(text) // 4  # ãŠãŠã‚ˆãã®æ¨å®š
        return len(text) // 4  # ãŠãŠã‚ˆãã®æ¨å®š
    
    def trim_conversation_history(self, messages):
        """ä¼šè©±å±¥æ­´ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å†…ã«åã‚ã‚‹"""
        if not encoding:
            return messages[-8:]  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒãªã„å ´åˆã¯ç›´è¿‘8ä»¶
        
        total_tokens = 0
        trimmed_messages = []
        
        # é€†é †ã§å‡¦ç†ã—ã¦ã€åˆ¶é™å†…ã®æœ€æ–°å±¥æ­´ã‚’ä¿æŒ
        for message in reversed(messages):
            message_tokens = self.count_tokens(json.dumps(message, ensure_ascii=False))
            if total_tokens + message_tokens > self.max_context_tokens:
                break
            total_tokens += message_tokens
            trimmed_messages.insert(0, message)
        
        return trimmed_messages
    
    async def generate_response(self, user_message, user_name, channel_name):
        """ChatGPTã«è¿”ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
        if not self.client:
            return "âŒ OpenAI APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        
        for attempt in range(self.retry_count):
            try:
                print(f'[GPT-4] {user_name}ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¿œç­”ä¸­ (è©¦è¡Œ {attempt + 1}/{self.retry_count}): {user_message[:50]}...')
            
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ãƒœãƒƒãƒˆã®æ€§æ ¼ã‚’å®šç¾©
                system_message = {
                    "role": "system",
                    "content": f"""ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ãçŸ¥è­˜è±Šå¯ŒãªDiscordãƒœãƒƒãƒˆã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ç‰¹å¾´:
- è¦ªã—ã¿ã‚„ã™ãã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå£èª¿ã§è©±ã™
- è³ªå•ã«ã¯å…·ä½“çš„ã§æœ‰ç”¨ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦çµµæ–‡å­—ã‚’ä½¿ç”¨ã—ã¦è¡¨ç¾ã‚’è±Šã‹ã«ã™ã‚‹
- æ—¥æœ¬èªã§è¿”ç­”ã™ã‚‹
- è¿”ç­”ã¯ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ãã™ã‚‹ï¼ˆ500æ–‡å­—ä»¥å†…ã‚’ç›®å®‰ï¼‰
- ã‚³ãƒ¼ãƒ‰ä¾‹ãŒå¿…è¦ãªå ´åˆã¯ã€é©åˆ‡ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦æä¾›ã™ã‚‹
- ä¸é©åˆ‡ãªå†…å®¹ã«ã¯å¿œç­”ã—ãªã„

ç¾åœ¨ã®çŠ¶æ³:
- ãƒãƒ£ãƒ³ãƒãƒ«: {channel_name}
- ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_name}
- æ—¥æ™‚: {datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}"""
                }
                
                # ä¼šè©±å±¥æ­´ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
                messages = [system_message]
                
                # æœ€è¿‘ã®å±¥æ­´ã‚’å«ã‚ã‚‹ï¼ˆGPT-4ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ´»ç”¨ï¼‰
                recent_history = self.response_history[-8:] if self.response_history else []
                for hist in recent_history:
                    messages.append({"role": "user", "content": hist["user_message"]})
                    messages.append({"role": "assistant", "content": hist["bot_response"]})
                
                # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                messages.append({"role": "user", "content": user_message})
                
                # ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å†…ã«å±¥æ­´ã‚’èª¿æ•´
                messages = self.trim_conversation_history(messages)
            
                # GPT-4 Chat Completions APIå‘¼ã³å‡ºã—
                response = self.client.chat.completions.create(
                    model="gpt-4-turbo-preview",
                    messages=messages,
                    max_tokens=self.max_tokens,
                    temperature=0.7,
                    user=f"discord_user_{hash(user_name) % 10000}"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼è­˜åˆ¥ç”¨
                )

                ai_response = response.choices[0].message.content.strip()

                # ä½¿ç”¨é‡æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
                usage = response.usage
                print(f'[API] ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ - å…¥åŠ›: {usage.prompt_tokens}, å‡ºåŠ›: {usage.completion_tokens}, åˆè¨ˆ: {usage.total_tokens}')
                
                # å±¥æ­´ã«è¿½åŠ ï¼ˆæœ€å¤§10ä»¶ã¾ã§ä¿æŒï¼‰
                self.response_history.append({
                    "user_name": user_name,
                    "user_message": user_message,
                    "bot_response": ai_response,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "tokens_used": usage.total_tokens
                })
                
                # å±¥æ­´ãŒ10ä»¶ã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                if len(self.response_history) > 10:
                    self.response_history = self.response_history[-10:]
                
                print(f'[GPT-4] å¿œç­”ç”Ÿæˆå®Œäº†: {ai_response[:50]}...')
                return ai_response
                
            except Exception as e:
                error_type = type(e).__name__
                error_message = str(e)
                
                print(f'[ERROR] APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{self.retry_count}): {error_type} - {error_message}')
                
                # ç‰¹å®šã®ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹å¯¾å¿œ
                if "rate_limit" in error_message.lower():
                    print(f'[WARNING] ãƒ¬ãƒ¼ãƒˆåˆ¶é™æ¤œå‡ºã€‚{self.rate_limit_delay * (attempt + 1)}ç§’å¾…æ©Ÿä¸­...')
                    await asyncio.sleep(self.rate_limit_delay * (attempt + 1))
                    continue
                elif "insufficient_quota" in error_message.lower():
                    return "âŒ OpenAI APIã®åˆ©ç”¨æ ã‚’è¶…éã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã®æ®‹é«˜ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                elif "invalid_api_key" in error_message.lower():
                    return "âŒ OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                elif "model_not_found" in error_message.lower() or "model does not exist" in error_message.lower():
                    return "âŒ GPT-4ãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã®æ¨©é™ã¾ãŸã¯ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                elif attempt == self.retry_count - 1:  # æœ€å¾Œã®è©¦è¡Œ
                    return f"âŒ GPT-4ã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_type}"
                
                # ãƒªãƒˆãƒ©ã‚¤å‰ã®çŸ­ã„å¾…æ©Ÿ
                await asyncio.sleep(0.5)
        
        return "âŒ è¤‡æ•°å›ã®è©¦è¡Œå¾Œã‚‚GPT-4ã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    def get_usage_stats(self):
        """ä½¿ç”¨çµ±è¨ˆã‚’å–å¾—"""
        total_tokens = sum(h.get('tokens_used', 0) for h in self.response_history)
        recent_responses = [h for h in self.response_history 
                           if (datetime.datetime.now() - datetime.datetime.fromisoformat(h['timestamp'])).seconds < 3600]
        recent_tokens = sum(h.get('tokens_used', 0) for h in recent_responses)
        
        return {
            "total_responses": len(self.response_history),
            "recent_responses": len(recent_responses),
            "total_tokens": total_tokens,
            "recent_tokens": recent_tokens,
            "estimated_cost_usd": total_tokens * 0.00001  # GPT-4 Turboã®ãŠãŠã‚ˆãã®ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆä»®å®šå€¤ã€å®Ÿéš›ã®æ–™é‡‘ã¯è¦ç¢ºèªï¼‰
        }

# GPT-4å¿œç­”è€…åˆæœŸåŒ–
chatgpt_responder = ChatGPTResponder(client) if client else None

@bot.event
async def on_ready():
    print(f'{bot.user} ã§ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ï¼')
    print('GPT-4é€£æºãƒœãƒƒãƒˆãŒèµ·å‹•ã—ã¾ã—ãŸ')
    print(f'å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«: {TARGET_CHANNEL_ID}')
    print(f'OpenAI API: {"âœ… è¨­å®šæ¸ˆã¿" if client else "âŒ æœªè¨­å®š"}')
    
    # ã‚µãƒ¼ãƒãƒ¼æƒ…å ±è¡¨ç¤º
    for guild in bot.guilds:
        print(f'ã‚µãƒ¼ãƒãƒ¼: {guild.name} (ID: {guild.id})')
        target_channel = bot.get_channel(TARGET_CHANNEL_ID)
        if target_channel and target_channel.guild == guild:
            print(f'  âœ… å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹: {target_channel.name}')
        else:
            print(f'  â“ å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«æœªç™ºè¦‹')

@bot.event
async def on_message(message):
    """ç‰¹å®šãƒãƒ£ãƒ³ãƒãƒ«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«GPT-4ã§è‡ªå‹•è¿”ç­”"""
    print(f'[DEBUG] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿ: {message.channel.id} vs {TARGET_CHANNEL_ID}')
    print(f'[DEBUG] é€ä¿¡è€…: {message.author} (ID: {message.author.id})')
    print(f'[DEBUG] ãƒœãƒƒãƒˆè‡ªèº«: {bot.user} (ID: {bot.user.id if bot.user else "None"})')
    print(f'[DEBUG] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹: "{message.content}"')
    
    # ãƒœãƒƒãƒˆè‡ªèº«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ç„¡è¦–
    if message.author == bot.user:
        print('[DEBUG] ãƒœãƒƒãƒˆè‡ªèº«ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—')
        return
    
    # å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ä»¥å¤–ã¯ç„¡è¦–
    if message.channel.id != TARGET_CHANNEL_ID:
        print(f'[DEBUG] å¯¾è±¡å¤–ãƒãƒ£ãƒ³ãƒãƒ« ({message.channel.id}) ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—')
        return
    
    # ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ã‚³ãƒãƒ³ãƒ‰ã¯ç„¡è¦–
    if not message.content.strip() or message.content.startswith('!'):
        print(f'[DEBUG] ç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—: "{message.content}"')
        return
    
    print(f'[DEBUG] å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œå‡º: {message.author} - {message.content[:50]}...')
    
    # GPT-4ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
    if not chatgpt_responder:
        print(f'[ERROR] GPT-4æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆOpenAI APIã‚­ãƒ¼æœªè¨­å®šï¼‰')
        await message.reply("âŒ GPT-4æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n"
                           "è¨­å®šæ–¹æ³•: `!gptinfo` ã‚³ãƒãƒ³ãƒ‰ã§è©³ç´°ç¢ºèª")
        return
    
    # å¿œç­”ä¸­ã®é‡è¤‡å‡¦ç†ã‚’é˜²ã
    if chatgpt_responder.is_responding:
        await message.add_reaction("â³")  # å‡¦ç†ä¸­ã‚’ç¤ºã™ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        return
    
    try:
        chatgpt_responder.is_responding = True
        
        # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ä¸­ã‚’è¡¨ç¤º
        async with message.channel.typing():
            # GPT-4ã«å¿œç­”ç”Ÿæˆã‚’ä¾é ¼
            ai_response = await chatgpt_responder.generate_response(
                user_message=message.content,
                user_name=str(message.author),
                channel_name=message.channel.name
            )
        
        # å¿œç­”ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ†å‰²
        if len(ai_response) > 2000:
            # Discord ã®æ–‡å­—æ•°åˆ¶é™ï¼ˆ2000æ–‡å­—ï¼‰ã‚’è¶…ãˆã‚‹å ´åˆã¯åˆ†å‰²
            chunks = [ai_response[i:i+1900] for i in range(0, len(ai_response), 1900)]
            for i, chunk in enumerate(chunks):
                if i == 0:
                    await message.reply(f"ğŸ¤– **GPT-4ã‹ã‚‰ã®è¿”ç­” (1/{len(chunks)})**\n\n{chunk}")
                else:
                    await message.channel.send(f"ğŸ¤– **GPT-4ã‹ã‚‰ã®è¿”ç­” ({i+1}/{len(chunks)})**\n\n{chunk}")
                
                # åˆ†å‰²é€ä¿¡ã®é–“ã«çŸ­ã„é–“éš”ã‚’ç©ºã‘ã‚‹
                if i < len(chunks) - 1:
                    await asyncio.sleep(1)
        else:
            # é€šå¸¸ã®è¿”ç­”
            await message.reply(f"ğŸ¤– **GPT-4ã‹ã‚‰ã®è¿”ç­”**\n\n{ai_response}")
        
        print(f'[SUCCESS] GPT-4å¿œç­”é€ä¿¡å®Œäº†')
        
    except Exception as e:
        print(f'[ERROR] ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}')
        await message.reply(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    finally:
        chatgpt_responder.is_responding = False
    
    # ã‚³ãƒãƒ³ãƒ‰ã‚‚å‡¦ç†ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    await bot.process_commands(message)

@bot.command(name='gptinfo')
async def gpt_info(ctx):
    """GPT-4æ©Ÿèƒ½ã®æƒ…å ±ã‚’è¡¨ç¤º"""
    embed = discord.Embed(
        title="ğŸ¤– GPT-4é€£æºæ©Ÿèƒ½",
        description="OpenAI GPT-4ã¨é€£æºã—ãŸAIå¿œç­”æ©Ÿèƒ½",
        color=0x00ff88
    )
    
    embed.add_field(name="ğŸ¯ å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«", value=f"<#{TARGET_CHANNEL_ID}>", inline=False)
    embed.add_field(name="ğŸ”§ å‹•ä½œæ–¹å¼", value="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠ•ç¨¿ â†’ è‡ªå‹•ã§ChatGPTãŒè¿”ç­”", inline=False)
    embed.add_field(name="ğŸ’¡ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", value="GPT-4 Turbo ğŸš€", inline=True)
    embed.add_field(name="ğŸ“ æ–‡å­—æ•°åˆ¶é™", value="2000æ–‡å­—ï¼ˆè‡ªå‹•åˆ†å‰²å¯¾å¿œï¼‰", inline=True)
    embed.add_field(name="ğŸ§  è¨˜æ†¶æ©Ÿèƒ½", value="ç›´è¿‘10å›ã®ä¼šè©±ã‚’è¨˜æ†¶", inline=True)
    
    # ä½¿ç”¨çµ±è¨ˆ
    if chatgpt_responder:
        stats = chatgpt_responder.get_usage_stats()
        embed.add_field(name="ğŸ“Š ä½¿ç”¨çµ±è¨ˆ", 
                       value=f"ç·å¿œç­”æ•°: {stats['total_responses']}\nç›´è¿‘1æ™‚é–“: {stats['recent_responses']}", 
                       inline=True)
        embed.add_field(name="ğŸ’° ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡", 
                       value=f"ç·è¨ˆ: {stats['total_tokens']:,}\nç›´è¿‘1æ™‚é–“: {stats['recent_tokens']:,}\næ¨å®šã‚³ã‚¹ãƒˆ: ${stats['estimated_cost_usd']:.4f}", 
                       inline=True)
        
        embed.add_field(name="âœ… APIçŠ¶æ…‹", value="æ­£å¸¸å‹•ä½œä¸­", inline=True)
    else:
        embed.add_field(name="âŒ APIçŠ¶æ…‹", value="æœªè¨­å®š", inline=True)
    
    embed.add_field(name="âš ï¸ æ³¨æ„äº‹é …", 
                   value="â€¢ ã‚³ãƒãƒ³ãƒ‰ï¼ˆ!ã§å§‹ã¾ã‚‹ï¼‰ã¯ç„¡è¦–\nâ€¢ ç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ç„¡è¦–\nâ€¢ APIåˆ©ç”¨æ–™ãŒç™ºç”Ÿã—ã¾ã™", 
                   inline=False)
    
    await ctx.send(embed=embed)

@bot.command(name='gptclear')
async def gpt_clear(ctx):
    """ChatGPTã®ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send("âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚")
        return
    
    if not chatgpt_responder:
        await ctx.send("âŒ ChatGPTæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    old_count = len(chatgpt_responder.response_history)
    chatgpt_responder.response_history = []
    
    embed = discord.Embed(
        title="ğŸ§¹ ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢å®Œäº†",
        description=f"ChatGPTã®ä¼šè©±å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã—ãŸ",
        color=0x00ff00
    )
    embed.add_field(name="å‰Šé™¤ã—ãŸå±¥æ­´æ•°", value=f"{old_count}ä»¶", inline=True)
    embed.add_field(name="åŠ¹æœ", value="æ–°ã—ã„ä¼šè©±ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™", inline=True)
    
    await ctx.send(embed=embed)

@bot.command(name='gpttest')
async def gpt_test(ctx):
    """ChatGPTæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    if ctx.channel.id != TARGET_CHANNEL_ID:
        await ctx.send("âŒ ã“ã®ã‚³ãƒãƒ³ãƒ‰ã¯å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«ã§ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚")
        return
    
    if not chatgpt_responder:
        await ctx.send("âŒ ChatGPTæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return
    
    test_message = "ã“ã‚“ã«ã¡ã¯ï¼ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚ç°¡å˜ã«è‡ªå·±ç´¹ä»‹ã‚’ã—ã¦ãã ã•ã„ã€‚"
    
    try:
        async with ctx.typing():
            response = await chatgpt_responder.generate_response(
                user_message=test_message,
                user_name=str(ctx.author),
                channel_name=ctx.channel.name
            )
        
        embed = discord.Embed(
            title="ğŸ§ª ChatGPTãƒ†ã‚¹ãƒˆçµæœ",
            description="ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¸ã®å¿œç­”",
            color=0x0099ff
        )
        embed.add_field(name="ğŸ“ ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", value=test_message, inline=False)
        embed.add_field(name="ğŸ¤– ChatGPTå¿œç­”", value=response, inline=False)
        
        await ctx.send(embed=embed)
        
    except Exception as e:
        await ctx.send(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")

if __name__ == '__main__':
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    
    print('=== GPT-4é€£æºDiscordãƒœãƒƒãƒˆèµ·å‹•ä¸­ ===')
    print(f'å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«: {TARGET_CHANNEL_ID}')
    print(f'Discord Token: {"âœ… è¨­å®šæ¸ˆã¿" if DISCORD_TOKEN else "âŒ æœªè¨­å®š"}')
    print(f'OpenAI API Key: {"âœ… è¨­å®šæ¸ˆã¿" if OPENAI_API_KEY else "âŒ æœªè¨­å®š"}')
    
    if not DISCORD_TOKEN:
        print('âŒ DISCORD_TOKENãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚')
        print('ğŸ“ æ‰‹é †:')
        print('   1. .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã¾ãŸã¯ç¢ºèª')
        print('   2. DISCORD_TOKEN=your_token_here ã‚’è¨­å®š')
        exit(1)
        
    if not OPENAI_API_KEY or OPENAI_API_KEY == 'your_openai_api_key_here':
        print('âš ï¸  OPENAI_API_KEYãŒæœªè¨­å®šã§ã™ã€‚')
        print('ğŸ“ æ‰‹é †:')
        print('   1. https://platform.openai.com/ ã§APIã‚­ãƒ¼ã‚’å–å¾—')
        print('   2. .envãƒ•ã‚¡ã‚¤ãƒ«ã« OPENAI_API_KEY=sk-your-key-here ã‚’è¨­å®š')
        print('   3. ChatGPTæ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚')
        print('ğŸ”„ ç¾åœ¨ã¯ChatGPTæ©Ÿèƒ½ç„¡åŠ¹ã§ãƒœãƒƒãƒˆã‚’èµ·å‹•ã—ã¾ã™...')
        
    print('âœ… è¨­å®šç¢ºèªå®Œäº†ã€‚ãƒœãƒƒãƒˆã‚’èµ·å‹•ã—ã¾ã™...')
    bot.run(DISCORD_TOKEN)