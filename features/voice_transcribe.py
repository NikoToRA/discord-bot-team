"""
éŸ³å£°æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ChatGPT Whisper APIã§æ–‡å­—èµ·ã“ã—
"""

import os
import tempfile
from openai import OpenAI
from config import REACTION_EMOJIS

async def transcribe_audio_with_whisper(audio_data, filename):
    """Whisper APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    temp_file_path = None
    try:
        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
        if not OPENAI_API_KEY:
            return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        client = OpenAI(api_key=OPENAI_API_KEY)

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        file_ext = os.path.splitext(filename)[1] if filename else '.mp3'
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as temp_file:
            temp_file.write(audio_data)
            temp_file_path = temp_file.name

        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        with open(temp_file_path, 'rb') as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text",
                language="ja",
                prompt="ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã‚’ã—ã¦ãã ã•ã„ã€‚å¥èª­ç‚¹ã‚‚é©åˆ‡ã«ä»˜ã‘ã¦ãã ã•ã„ã€‚"
            )

        return transcription.strip()

    except Exception as e:
        print(f"éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if temp_file_path and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
            except Exception as e:
                print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

async def handle_voice_transcription(message, bot):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—å‡¦ç†"""
    # éŸ³å£°æ·»ä»˜ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    if not message.attachments:
        return False

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
    audio_attachment = None
    for attachment in message.attachments:
        if any(attachment.filename.lower().endswith(ext) for ext in ['.mp3', '.wav', '.ogg', '.m4a', '.flac']):
            audio_attachment = attachment
            break

    if not audio_attachment:
        return False

    try:
        # å‡¦ç†é–‹å§‹ã‚’é€šçŸ¥
        await message.add_reaction(REACTION_EMOJIS['processing'])

        # éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        audio_data = await audio_attachment.read()

        # Whisper APIã§æ–‡å­—èµ·ã“ã—
        transcribed_text = await transcribe_audio_with_whisper(audio_data, audio_attachment.filename)

        # çµæœã‚’é€ä¿¡
        if transcribed_text.strip():
            await message.reply(f"**ğŸ¤ éŸ³å£°æ–‡å­—èµ·ã“ã—çµæœ:**\n```\n{transcribed_text}\n```")
        else:
            await message.reply("éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        # å‡¦ç†å®Œäº†ã‚’é€šçŸ¥
        await message.remove_reaction(REACTION_EMOJIS['processing'], bot.user)
        await message.add_reaction(REACTION_EMOJIS['success'])
        return True

    except Exception as e:
        print(f"éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        await message.reply("éŸ³å£°ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        await message.remove_reaction(REACTION_EMOJIS['processing'], bot.user)
        await message.add_reaction(REACTION_EMOJIS['error'])
        return False

async def auto_add_voice_reaction(message):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ·»ä»˜ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è‡ªå‹•ã§ğŸ¤ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ """
    if message.attachments:
        for attachment in message.attachments:
            if any(attachment.filename.lower().endswith(ext) for ext in ['.mp3', '.wav', '.ogg', '.m4a', '.flac']):
                await message.add_reaction(REACTION_EMOJIS['voice_transcribe'])
                return True
    return False